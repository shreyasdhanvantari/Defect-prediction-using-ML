# ğŸ§  Software Defect Prediction using Machine Learning  
[![Python](https://img.shields.io/badge/Python-3.11-blue.svg)](https://www.python.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Build](https://img.shields.io/badge/Build-Passing-brightgreen.svg)]()
[![Platform](https://img.shields.io/badge/Platform-Colab%20%7C%20VS%20Code-orange.svg)]()

> Automatically predict defect-prone source code files by analyzing code metrics and version-control history.  
> Built entirely in **Python**, with results verified using a real GitHub repository (`psf/requests`).

---

## ğŸ“‹ Overview

This project predicts **which source code files are most likely to contain defects (bugs)** by combining:
- ğŸ§® **Static metrics** â€“ Lines of code, cyclomatic complexity, maintainability index, PEP8 violations  
- ğŸ§  **Process metrics** â€“ Commit frequency, code churn, authors, last modification timestamp  
- ğŸ **Defect labels** â€“ Generated automatically by scanning commit messages containing â€œfixâ€, â€œbugâ€, etc.  

Using these metrics, two ML models (Logistic Regression and Random Forest) are trained to produce a **risk score (0-1)** for each file.

---

## ğŸ§© Project Structure

defect-predictor/
â”‚
â”œâ”€â”€ data/                 # Extracted datasets
â”‚   â”œâ”€â”€ static.csv        # Code metrics
â”‚   â”œâ”€â”€ process.csv       # Git metrics
â”‚   â”œâ”€â”€ labels.csv        # Bug-fix labels
â”‚   â””â”€â”€ merged_dataset.csv
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extract/
â”‚   â”‚   â”œâ”€â”€ static_metrics.py     # Extract static code metrics
â”‚   â”‚   â””â”€â”€ process_metrics.py    # Extract process metrics
â”‚   â”œâ”€â”€ label/
â”‚   â”‚   â””â”€â”€ labeler.py            # Generate defect labels
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ train.py              # Train ML models
â”‚   â”‚   â””â”€â”€ predict.py            # Predict file risk
â”‚   â”œâ”€â”€ report/
â”‚   â”‚   â”œâ”€â”€ make_report.py        # Generate HTML report
â”‚   â”‚   â””â”€â”€ app.py                # Flask dashboard (optional)
â”‚   â””â”€â”€ utils/                    # Helper functions (optional)
â”‚
â”œâ”€â”€ artifacts/            # Saved trained models & metrics
â”‚   â”œâ”€â”€ rf.pkl
â”‚   â”œâ”€â”€ logreg.pkl
â”‚   â””â”€â”€ metrics.csv
â”‚
â”œâ”€â”€ reports/              # Predictions & visual reports
â”‚   â”œâ”€â”€ risk.csv
â”‚   â””â”€â”€ report.html
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository
git clone https://github.com/<your-username>/defect-predictor.git
cd defect-predictor

### 2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

### 3ï¸âƒ£ Clone a Target Repository for Analysis
git clone https://github.com/psf/requests.git target_repo

### 4ï¸âƒ£ Extract Metrics & Labels
python -m src.extract.static_metrics --repo ./target_repo --out data/static.csv
python -m src.extract.process_metrics --repo ./target_repo --out data/process.csv
python -m src.label.labeler --repo ./target_repo --out data/labels.csv

### 5ï¸âƒ£ Train Models
python -m src.models.train --features data/static.csv data/process.csv --labels data/labels.csv --out artifacts

### 6ï¸âƒ£ Predict Defect Risk
python -m src.models.predict --model artifacts/rf.pkl --features data/static.csv data/process.csv --out reports/risk.csv

### 7ï¸âƒ£ Generate HTML Report
python -m src.report.make_report --risk reports/risk.csv --out reports/report.html

Then open **reports/report.html** to view the risk chart and file-wise predictions.

---

## ğŸ§  Results Summary

| Model | ROC-AUC | PR-AUC | F1-Score |
|--------|----------|---------|-----------|
| Logistic Regression | 0.74 | 0.63 | 0.58 |
| Random Forest | **0.86** | **0.71** | **0.69** |

### ğŸ” Insights
- High **code churn** and **commit frequency** correlate strongly with defects.  
- Large, complex files (high LOC, avg_CC) are riskier.  
- Multiple contributors (**authors**) also increase defect likelihood.

---

## ğŸ“Š Example Output

| file | risk | defect_prone |
|------|------|---------------|
| requests/models.py | 0.87 | 1 |
| requests/adapters.py | 0.76 | 1 |
| requests/utils.py | 0.24 | 0 |

### ğŸ¨ Feature Importance
1. Code Churn  
2. Commit Count  
3. Lines of Code (LOC)  
4. Cyclomatic Complexity  
5. Number of Authors  

---

## ğŸ§° Tech Stack

| Category | Tools |
|-----------|-------|
| Language | Python 3.11 |
| ML Libraries | scikit-learn, pandas, numpy |
| Static Analysis | radon, pycodestyle |
| Repo Mining | PyDriller |
| Visualization | matplotlib, seaborn |
| Web/Dashboard | Flask |
| Environment | Google Colab / VS Code |

---

## ğŸš€ Future Enhancements
- Integrate with CI/CD for automatic defect scanning on each push.  
- Use NLP to improve commit message labeling.  
- Apply temporal validation (train on older commits, predict on newer).  
- Extend to multiple repositories for cross-project learning.

---

## ğŸ‘¨â€ğŸ’» Author

**Shreyas Dhanvantari**  
Master of Engineering â€“ Electrical & Computer Engineering  
Ontario Tech University, Canada  

ğŸ“« Email: hanvantari.svd@gmail.com

---

## ğŸ“œ License
Distributed under the **MIT License**. See [LICENSE](LICENSE) for more information.

---

â­ **If you found this useful, give it a star on GitHub!**
