# -*- coding: utf-8 -*-
"""Defect Prediction Using ML

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VpOuqdXy2ZDaoKMB6LJAVQBd5Lxy5kBE
"""

from google.colab import files
uploaded = files.upload()

# Commented out IPython magic to ensure Python compatibility.
!unzip defect-predictor-starter.zip -d defect-predictor
# %cd defect-predictor

!ls

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/defect-predictor/defect-predictor

!pip install -r requirements.txt
!python -c "import pandas, sklearn, flask; print('‚úÖ Environment OK')"

!git clone https://github.com/psf/requests.git target_repo

!mkdir -p data

!python -m src.extract.static_metrics --repo ./target_repo --out data/static.csv

!mkdir -p data
!ls data

!python -m src.label.labeler --repo ./target_repo --out data/labels.csv

!head -n 10 data/labels.csv

# patch src/extract/process_metrics.py to use added_lines/deleted_lines
from pathlib import Path

code = r"""
import argparse
import pandas as pd
from pydriller import Repository
from datetime import datetime

def mine(repo_path: str) -> pd.DataFrame:
    rows = {}
    for commit in Repository(repo_path).traverse_commits():
        for m in commit.modified_files:
            fpath = m.new_path or m.old_path
            if not fpath or not fpath.endswith(".py"):
                continue
            r = rows.get(fpath, dict(file=fpath, commits=0, added=0, removed=0, authors=set(), last_ts=None))
            r["commits"] += 1
            # PyDriller fields:
            added = getattr(m, "added_lines", 0) or 0
            deleted = getattr(m, "deleted_lines", 0) or 0
            r["added"] += added
            r["removed"] += deleted
            author_sig = f"{(commit.author.name or '')}<{(commit.author.email or '')}>"
            r["authors"].add(author_sig)
            r["last_ts"] = commit.author_date
            rows[fpath] = r

    out = []
    for v in rows.values():
        out.append({
            "file": v["file"],
            "commits": v["commits"],
            "churn": v["added"] + v["removed"],
            "authors": len(v["authors"]),
            "last_ts": v["last_ts"].isoformat() if isinstance(v["last_ts"], datetime) else None
        })
    return pd.DataFrame(out)

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--repo", required=True, help="Path to a local git repository")
    ap.add_argument("--out", required=True, help="Output CSV path")
    args = ap.parse_args()

    df = mine(args.repo)
    df.to_csv(args.out, index=False)
    print(f"[process_metrics] Wrote: {args.out} ({len(df)} rows)")

if __name__ == "__main__":
    main()
"""
Path("src/extract/process_metrics.py").write_text(code, encoding="utf-8")
print("‚úÖ Patched src/extract/process_metrics.py")

# ensure data folder exists
!mkdir -p data

# static metrics (you already ran this, safe to run again)
!python -m src.extract.static_metrics --repo ./target_repo --out data/static.csv
!head -n 5 data/static.csv

# process metrics (now with the fix)
!python -m src.extract.process_metrics --repo ./target_repo --out data/process.csv
!head -n 5 data/process.csv

# labels (you have them, re-run is fine)
!python -m src.label.labeler --repo ./target_repo --out data/labels.csv
!head -n 5 data/labels.csv

!mkdir -p artifacts
!python -m src.models.train --features data/static.csv data/process.csv --labels data/labels.csv --out artifacts
!cat artifacts/metrics.csv

!mkdir -p reports

!python -m src.models.predict --model artifacts/rf.pkl \
  --features data/static.csv data/process.csv --out reports/risk.csv

from google.colab import files
files.download("data/static.csv")
files.download("data/process.csv")
files.download("data/labels.csv")
files.download("reports/risk.csv")  # predicted results

import pandas as pd
static = pd.read_csv("data/static.csv")
print("Static Metrics Shape:", static.shape)
static.head(20).style.background_gradient(cmap="Blues")

process = pd.read_csv("data/process.csv")
print("Process Metrics Shape:", process.shape)
process.head(20).style.background_gradient(cmap="Greens")

labels = pd.read_csv("data/labels.csv")
print("Labels Shape:", labels.shape)
labels.head(20).style.background_gradient(cmap="Oranges")

# --- Import Required Library ---
import pandas as pd
from google.colab import files

# --- Load Datasets ---
static = pd.read_csv("data/static.csv")
process = pd.read_csv("data/process.csv")
labels = pd.read_csv("data/labels.csv")

print("Datasets Loaded Successfully:")
print(f"Static: {static.shape} | Process: {process.shape} | Labels: {labels.shape}")

# --- Merge All into One DataFrame ---
df = static.merge(process, on="file", how="outer") \
           .merge(labels, on="file", how="left") \
           .fillna(0)

print("\n‚úÖ Merged Dataset Created:")
print(f"Final Shape: {df.shape}")

# --- Preview First 20 Rows with Colored Styling ---
df_preview = df.head(50).style.background_gradient(cmap="Purples")
display(df_preview)

# --- Save and Download Merged Dataset ---
output_path = "data/merged_dataset.csv"
df.to_csv(output_path, index=False)
print(f"\nüìÅ Merged dataset saved as: {output_path}")

# Download to your computer
#files.download(output_path)

!head -n 15 reports/risk.csv

!python -m src.report.make_report --risk reports/risk.csv --out reports/report.html

!cat artifacts/metrics.csv

!head -n 15 reports/risk.csv

import joblib, pandas as pd, matplotlib.pyplot as plt

# Load model and features
rf = joblib.load("artifacts/rf.pkl")

df_static = pd.read_csv("data/static.csv")
df_process = pd.read_csv("data/process.csv")

# Merge and clean
df = df_static.merge(df_process, on="file", how="outer").fillna(0)
X = df.drop(columns=["file","last_ts"], errors="ignore")

# Calculate importances
importances = rf.feature_importances_
feat_imp = pd.Series(importances, index=X.columns).sort_values(ascending=False)

# Plot
plt.figure(figsize=(8,4))
feat_imp.head(10).plot(kind="barh")
plt.gca().invert_yaxis()
plt.title("Top 10 Feature Importances (Random Forest)")
plt.xlabel("Importance")
plt.tight_layout()
plt.show()

feat_imp.head(10)

!python -m src.report.app

# Preview inside Colab
from IPython.display import HTML
HTML(filename='reports/report.html')

# Or download it to your computer
#from google.colab import files
#files.download('reports/report.html')